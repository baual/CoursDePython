{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0664550b918e669b189e79c6fcf356c08dd1ee25478e77016cbd798931c4b093e",
   "display_name": "Python 3.9.4 64-bit ('DataScience': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "664550b918e669b189e79c6fcf356c08dd1ee25478e77016cbd798931c4b093e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous importerons ensuite Matplotlib pour tracer nos données\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Ensuite, nous importerons NumPy, une bibliothèque afin de traiter de grandes matrices numériques (images) :\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: Python 3.9 users will need to add '-c=conda-forge' for installation \n",
    "# conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n",
    "# use this : conda install pytorch torchvision cudatoolkit -c=conda-forge\n",
    "\n",
    "#Importez PyTorch pour former et traiter des modèles Deep Learning et d’intelligence artificielle :\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Importez torchvision (composante de pyTorch) pour traiter les images et les manipuler (rogner, redimensionner) :\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "\n",
    "#Importez une bibliothèque d’images Python (PIL) pour visualiser les images :\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#Enfin, nous ajoutons deux bibliothèques qui garantissent que les tracés s’affichent en ligne et en haute résolution :\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant que nous savons comment nettoyer et séparer les données, nous pouvons réellement appliquer ces principes à notre projet de classification des roches.\n",
    "\n",
    "#Commençons par télécharger toutes les données dont nous disposons sur les images de roches. Ensuite, nous allons le placer dans le même dossier que votre fichier Jupyter Notebook. Accédez à ce stockage d’objets BLOB Azure et téléchargez le dossier Data.zip. Décompressez-le et placez-le dans le même dossier que votre fichier Jupyter Notebook.\n",
    "\n",
    "#Comme nos photos de roches sont de tailles différentes (petites, moyennes et grandes), nous recadrons les images pour qu’elles soient de la même taille (224 × 224 pixels). Nous redimensionnons les images, car les ordinateurs s’attendent à ce que les images soient de la même taille. Si la taille des images varie, elles ne sont pas aussi faciles à traiter par l’ordinateur.\n",
    "\n",
    "#Nous allons redimensionner les images dans la première partie du code. Au bas du code, vous pouvez voir que nous séparons les données en une variable d’apprentissage et une variable de test.\n",
    "\n",
    "# Tells the machine what folder contains the image data.\n",
    "data_dir = './data'\n",
    "\n",
    "# Function to read the data; crop and resize the images; and then split it into test and train chunks.\n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "    # This line of code transforms the images.\n",
    "    train_transforms = transforms.Compose([\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.Resize(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                      ])\n",
    "\n",
    "    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# We're using 20% of data for testing.\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant que nous avons chargé les images dans l’ordinateur, examinons quelques-unes d’entre elles. Nous leur attribuerons des étiquettes indiquant le type de roche que contiennent les photos.\n",
    "\n",
    "# Le bloc de code suivant lit les images et attribue ensuite à chaque image un type de roche correspondant. Le code semble long, mais c’est parce qu’il doit faire correspondre chaque image de roche avec le type de roche approprié, en fonction du dossier dans lequel elle se trouve.\n",
    "\n",
    "# Transform the new image into numbers and resize it.\n",
    "test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                    ])\n",
    "\n",
    "# A function to randomly select a set of images.\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels\n",
    "\n",
    "# Le code suivant vous montre en fait quelques images que vous avez chargées dans le programme :\n",
    "# How many images do you want to see? It's set to 5, but you can change the number.\n",
    "images, labels = get_random_images(5)\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "classes=trainloader.dataset.classes\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "# Nous utilisons ici la bibliothèque PIL pour manipuler les images, afin qu’elles soient attrayantes lorsque nous les imprimons. Nous utilisons le script plt.show pour imprimer les images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À présent, créons un réseau neuronal/Deep Learning pour découvrir les associations entre les caractéristiques (par exemple, les courbes, les arêtes et les textures) et chaque type de roche.\n",
    "\n",
    "#Le fonctionnement d’un réseau neuronal est très similaire à celui de notre cerveau. Le cerveau humain se compose de neurones ou de cellules nerveuses qui transmettent et traitent les informations qu’il reçoit de nos sens. La plupart des cellules nerveuses sont organisées de manière à former un réseau nerveux dans notre cerveau. Les nerfs transmettent des impulsions électriques d’un neurone au neurone suivant.\n",
    "\n",
    "#Exécutez le code suivant pour indiquer à votre ordinateur la méthode la plus efficace pour créer un réseau neuronal :\n",
    "# Determine whether you're using a CPU or a GPU to build the deep learning network.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les réseaux neuronaux ont des millions de neurones et de nerfs. Pour créer un réseau neuronal fonctionnel, nous allons les relier en deux étapes :\n",
    "#    Générer l’ensemble des neurones.\n",
    "#    Connecter les neurones de façon appropriée (il existe des milliers de façons de relier les neurones).\n",
    "# Builds all the neurons.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# The parameters of our deep learning model.\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 2),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)\n",
    "print('done')\n",
    "# Le réseau neuronal effectue de nombreux allers-retours jusqu’à ce qu’il apprenne les meilleures associations (câblages) entre les caractéristiques et les types de roches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant que nous avons créé un réseau neuronal et présenté au programme les différentes caractéristiques de roches, nous devons désormais effectuer l’apprentissage du programme. Dans cette étape, nous utilisons nos données d’apprentissage pour augmenter la précision de notre programme en matière de classification des roches spatiales.\n",
    "\n",
    "#Copiez le code suivant dans une cellule, puis exécutez-le. Soyez attentif à la variable epochs dans le code. Cette variable indique au programme le nombre de fois où il faut rechercher des associations dans les caractéristiques. Ce nombre est initialement défini sur 5, mais vous pouvez l’augmenter pour augmenter la précision. Toutefois, si vous augmentez ce nombre, le code s’exécutera beaucoup plus lentement.\n",
    "epochs = 5\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "\n",
    "        steps += 1\n",
    "        print('Training step ', steps)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une grande partie des avantages de l’IA réside dans son degré de précision dans la prédiction de résultats corrects. Dans notre cas, la précision est la probabilité que l’ordinateur identifie correctement une roche affichée sur une image comme étant du même type que celui déterminé manuellement par des scientifiques. Une précision de 0,96 signifie que 96 % des types de roches sont prédits correctement et que 4 % sont mal classifiés.\n",
    "\n",
    "#Le code suivant calcule la précision de notre système IA pour la classification des roches :\n",
    "print(accuracy/len(testloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme vous pouvez le voir, la précision de ce modèle est très élevée. C’est ce que nous voulons, car cela signifie que le modèle fait un bon travail d’élaboration de prédictions.\n",
    "\n",
    "# Même si 96 % est un pourcentage élevé, vous pouvez prendre quelques mesures pour augmenter davantage la précision :\n",
    "\n",
    "#Ajoutez d’autres images pour effectuer l’apprentissage des modèles IA.\n",
    "#Augmentez l’époque (nombre d’itérations d’apprentissage pour le Deep Learning).\n",
    "#Maintenant que nous avons créé le réseau neuronal et testé sa précision, nous allons l’enregistrer :\n",
    "torch.save(model, 'aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons maintenant prédire les types de roches. Pour prédire les types de roches affichés dans une nouvelle image, il faut réaliser les étapes suivantes :\n",
    "#   Convertir la nouvelle image en nombres.\n",
    "#   Transformer l’image : la rogner et la redimensionner sur 224 × 224 pixels.\n",
    "#   Extraire les fonctionnalités et les caractéristiques de l’image.\n",
    "#   Prédisez le type de roche affiché dans l’image en utilisant les associations que nous avons apprises à l’étape 2.\n",
    "\n",
    "#Le code suivant charge notre réseau neuronal :\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=torch.load('aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ce code crée une fonction qui prédit le nouveau type d’image :\n",
    " def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisissons cinq images aléatoires et voyons si notre modèle peut déterminer le type de roche.\n",
    "\n",
    "#Le code suivant obtient cinq images aléatoires et stocke leurs données dans des variables. Nous utilisons cinq images pour tester notre système d’intelligence artificielle, mais vous pouvez choisir n’importe quel nombre d’images. Après avoir exécuté le code suivant, remplacez le nombre par 10, puis réexécutez le code.\n",
    "images, labels = get_random_images(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce code visualise les nouvelles images et ajoute des légendes indiquant le type de roche que le modèle repère sur la photo.\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels = get_random_images(5)\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "\n",
    "classes=trainloader.dataset.classes\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "    sub.set_title(str(classes[index]) + \":\" + str(res))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "plt.show()\n",
    "# Les exemples d’images sont étiquetés Type de roche réel : True/False.\n",
    "# True et False indiquent si notre système d’intelligence artificielle a correctement classifié la roche qui se trouve dans l’image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}